# ü©∫ Medical Chatbot: End-to-End Solution

This project is an AI-powered medical chatbot designed to assist users with general medical inquiries. It integrates cutting-edge technologies, including OpenAI, Pinecone, Hugging Face, and LangChain, to provide accurate, contextual, and human-like responses.

---

## üöÄ Features

- **Conversational AI**: Delivers human-like medical assistance using OpenAI's GPT models.
- **Semantic Search**: Leverages Pinecone for efficient and scalable vector-based search.
- **Custom Embeddings**: Uses Hugging Face models to create domain-specific embeddings.
- **LangChain**: Manages workflows, pipelines, and integrations for seamless interaction between components.
- **End-to-End Workflow**: From user query processing to response generation, ensuring a smooth user experience.

---

## üõ†Ô∏è Technologies Used

- **[OpenAI](https://openai.com/)**: GPT models for generating accurate responses.
- **[Pinecone](https://www.pinecone.io/)**: Vector database for fast semantic search and document retrieval.
- **[Hugging Face](https://huggingface.co/)**: Pretrained transformer models for embeddings (e.g., `sentence-transformers`).
- **[LangChain](https://www.langchain.com/)**: Framework for chaining prompts, memory, and APIs.

---

## üìã Prerequisites

1. Python 3.8 or higher
2. Virtual Environment (e.g., `venv` or `conda`)
3. API keys for:
   - OpenAI
   - Pinecone
4. Install the dependies from requirement.txt file


## üß† Architecture Overview
1. User Query: A user submits a query via the chatbot interface.
2. Embedding Generation: Hugging Face's transformer models encode the query into a vector representation.
3. Preprocessed medical data is also encoded and stored in Pinecone for retrieval.
4. Semantic Search: Pinecone searches for relevant documents or information based on the query embedding.
5. Response Generation: OpenAI‚Äôs GPT models generate responses, leveraging context retrieved by LangChain and Pinecone.
6. Output: A natural language response is returned to the user.
